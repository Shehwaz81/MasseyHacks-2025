# MasseyHacks-202

We are developing a web application that captures live video from the user’s camera, detects and recognizes 
sign‑language gestures using an on‑device AI pipeline, and translates them into text (and optionally speech) in real time
